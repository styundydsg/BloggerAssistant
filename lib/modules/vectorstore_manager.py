"""å‘é‡æ•°æ®åº“ç®¡ç†æ¨¡å— - å¤„ç†FAISSå‘é‡æ•°æ®åº“çš„åˆ›å»ºã€åŠ è½½å’Œæ›´æ–°"""

import os
from typing import Optional
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.schema import Document

from .config import CONFIG
from .document_loader import load_documents



def initialize_vectorstore() -> FAISS:
    """åˆå§‹åŒ–æˆ–åŠ è½½å‘é‡æ•°æ®åº“"""
    embeddings = _get_embeddings()
    
    if _vectorstore_exists():
        vectorstore = _load_existing_vectorstore(embeddings)
        _update_vectorstore_if_needed(vectorstore)
        return vectorstore
    else:
        return _create_new_vectorstore(embeddings)

def _get_embeddings() -> HuggingFaceEmbeddings:
    """è·å–åµŒå…¥æ¨¡å‹"""
    return HuggingFaceEmbeddings(
        model_name=CONFIG["MODEL_DIR"],
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True}
    )

def _vectorstore_exists() -> bool:
    """æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨"""
    return os.path.exists(CONFIG["VECTORSTORE_PATH"]) and os.path.isdir(CONFIG["VECTORSTORE_PATH"])

def _load_existing_vectorstore(embeddings: HuggingFaceEmbeddings) -> FAISS:
    """åŠ è½½ç°æœ‰çš„å‘é‡æ•°æ®åº“"""
    try:
        vectorstore = FAISS.load_local(
            CONFIG["VECTORSTORE_PATH"], 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        print("æˆåŠŸåŠ è½½ç°æœ‰å‘é‡æ•°æ®åº“")
        return vectorstore
    except Exception:
        print("å‘é‡æ•°æ®åº“æŸåï¼Œé‡å»ºä¸­...")
        return None

def _update_vectorstore_if_needed(vectorstore: FAISS) -> None:
    """æ£€æŸ¥å¹¶æ›´æ–°å‘é‡æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    data = load_documents()
    
    existing_files = {doc.metadata['source'] for doc in vectorstore.docstore._dict.values()}
    current_files = {doc.metadata['source'] for doc in data}
    new_files = current_files - existing_files
    modified_files = set()

    # æ£€æŸ¥ä¿®æ”¹çš„æ–‡ä»¶
    for doc in data:
        source = doc.metadata['source']
        if source in existing_files:
            existing_doc = next(d for d in vectorstore.docstore._dict.values() 
                               if d.metadata['source'] == source)
            if doc.metadata['last_modified'] > existing_doc.metadata.get('last_modified', 0):
                modified_files.add(source)
    
    # å¦‚æœæœ‰æ–°æ–‡ä»¶æˆ–ä¿®æ”¹çš„æ–‡ä»¶ï¼Œè¿›è¡Œæ›´æ–°
    if new_files or modified_files:
        updated_docs = [doc for doc in data 
                       if doc.metadata['source'] in (new_files | modified_files)]
        vectorstore.add_documents(updated_docs)
        print(f"ğŸ†• å¢é‡æ›´æ–° {len(updated_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
        vectorstore.save_local(CONFIG["VECTORSTORE_PATH"])
    else:
        print("â© æœªæ£€æµ‹åˆ°æ–‡ä»¶å˜æ›´ï¼Œæ— éœ€æ›´æ–°")

def _create_new_vectorstore(embeddings: HuggingFaceEmbeddings) -> FAISS:
    """åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“"""
    from langchain.indexes import VectorstoreIndexCreator
    
    data = load_documents()
    
    index_creator = VectorstoreIndexCreator(
        embedding=embeddings,
        vectorstore_cls=FAISS,
    )
    index = index_creator.from_documents(data)
    vectorstore = index.vectorstore
    vectorstore.save_local(CONFIG["VECTORSTORE_PATH"])
    print(f"å·²åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“ï¼ŒåŒ…å« {len(vectorstore.index_to_docstore_id)} ä¸ªæ–‡æ¡£")
    return vectorstore
